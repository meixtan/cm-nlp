{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing\n",
        "\n",
        "We annotate for 5 dimensions and prepare labeled datasets for each dimension:\n",
        "\n",
        "*   cm_labeled\n",
        "*   punitiveness_labeled\n",
        "*   praise_labeled\n",
        "*   otr_labeled\n",
        "*   rationale_labeled\n",
        "\n"
      ],
      "metadata": {
        "id": "p3dICzjAmBWf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wF2frPiAwUR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Select one dataset\n",
        "df = pd.read_csv(\"cm_labeled.csv\")\n",
        "df = df.rename(columns={'cm': 'label'})\n",
        "# Give each row a prediction index\n",
        "df['pred_index'] = range(1, len(df) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZQ61kgdmXBZ"
      },
      "outputs": [],
      "source": [
        "# Mask out numbers and student identifiers\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub('[0-9]+', \"<num>\", x))\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub('(student )[a-z][^a-z]', \"<student>\", x))\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub('(Student )[A-Z]', \"<student>\", x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility\n",
        "\n",
        "Install packages and set up the train, predict, and evaluation functions."
      ],
      "metadata": {
        "id": "7XdbL-2Qolqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP15KR1eKuRN"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.24.0\n",
        "!pip install simpletransformers==0.63.11\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "from argparse import ArgumentParser\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from sys import exit\n",
        "import logging\n",
        "import torch\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKlt6aZ9LpeO"
      },
      "outputs": [],
      "source": [
        "def pearson_corr(preds, labels):\n",
        "    return pearsonr(preds, labels)[0]\n",
        "\n",
        "def spearman_corr(preds, labels):\n",
        "    return spearmanr(preds, labels)[0]\n",
        "\n",
        "def accuracy(preds, labels):\n",
        "    return sum([p == l for p, l in zip(preds, labels)]) /len(labels)\n",
        "\n",
        "def precision(preds, labels):\n",
        "    return precision_score(y_true=labels, y_pred=preds)#, average = \"weighted\")\n",
        "\n",
        "def recall(preds, labels):\n",
        "    return recall_score(y_true=labels, y_pred=preds)#, average = \"weighted\")\n",
        "\n",
        "def f1(preds, labels):\n",
        "    return f1_score(y_true=labels, y_pred=preds)#, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENW60SNpLsz2"
      },
      "outputs": [],
      "source": [
        "def train(colname, train_df, eval_df, text_cols,\n",
        "          output_dir, model=\"roberta\", num_labels=2,\n",
        "          num_train_epochs=10,\n",
        "          train_batch_size=8, gradient_accumulation_steps=2,\n",
        "          max_seq_length=512,\n",
        "          cross_validate=False,\n",
        "          balance_labels_trim=False,\n",
        "          balance_labels_weights=False,\n",
        "          weights = None):\n",
        "    print(\"Train size: %d\" % len(train_df))\n",
        "    print(\"Eval size: %d\" % len(eval_df))\n",
        "\n",
        "    print(train_df.head())\n",
        "    print(eval_df.head())\n",
        "\n",
        "    print(\"Is CUDA available? \" + str(torch.cuda.is_available()))\n",
        "\n",
        "    print(\"balance_labels_trim: \" + str(balance_labels_trim))\n",
        "    if balance_labels_trim:\n",
        "        most_common = train_df[\"labels\"].value_counts().idxmax()\n",
        "        print(\"Most common label is: %s\" % most_common)\n",
        "        most_common_df = train_df[train_df[\"labels\"]==most_common]\n",
        "        concat_list = [most_common_df]\n",
        "        for label, group in train_df[train_df[\"labels\"]!=most_common].groupby(\"labels\"):\n",
        "            concat_list.append(group.sample(replace=True, n=len(most_common_df)))\n",
        "        train_df = pd.concat(concat_list)\n",
        "        print(\"Train size: %d\" % len(train_df))\n",
        "        print(train_df[\"labels\"].value_counts())\n",
        "\n",
        "    # Shuffle training data\n",
        "    train_df = train_df.sample(frac=1)\n",
        "    save_dir = output_dir + \"/\" + colname + \"_train_size=\" + str(len(train_df))\n",
        "\n",
        "    model_args = ClassificationArgs()\n",
        "    model_args.reprocess_input_data = True\n",
        "    model_args.overwrite_output_dir = True\n",
        "    model_args.evaluate_during_training = True  # change if needed\n",
        "    model_args.max_seq_length = int(max_seq_length / len(text_cols))\n",
        "    model_args.num_train_epochs = num_train_epochs\n",
        "    model_args.evaluate_during_training_steps = int(len(train_df) / train_batch_size) # after each epoch\n",
        "    model_args.save_eval_checkpoints = False\n",
        "    model_args.save_model_every_epoch = False\n",
        "    model_args.wandb_project = colname\n",
        "    model_args.train_batch_size = train_batch_size\n",
        "    model_args.output_dir = save_dir\n",
        "    model_args.best_model_dir = save_dir +\"/best_model\"\n",
        "    model_args.cache_dir = save_dir + \"/cache\"\n",
        "    model_args.tensorboard_dir = save_dir + \"/tensorboard\"\n",
        "    model_args.regression = num_labels == 1\n",
        "    model_args.gradient_accumulation_steps = gradient_accumulation_steps\n",
        "    model_args.wandb_kwargs = {\"reinit\": True}\n",
        "    model_args.fp16 = False\n",
        "    model_args.fp16_opt_level = \"O0\"\n",
        "    model_args.no_cache = False\n",
        "    model_args.no_save = cross_validate\n",
        "    model_args.save_optimizer_and_scheduler = True\n",
        "\n",
        "    print(\"balance_labels_weights: \" + str(weights))\n",
        "    if balance_labels_weights:\n",
        "      model = ClassificationModel(model.split(\"-\")[0], model,\n",
        "                                use_cuda=torch.cuda.is_available(),\n",
        "                                num_labels=num_labels,\n",
        "                                args=model_args, weight=weights)\n",
        "    else:\n",
        "      model = ClassificationModel(model.split(\"-\")[0], model,\n",
        "                                use_cuda=torch.cuda.is_available(),\n",
        "                                num_labels=num_labels,\n",
        "                                args=model_args)\n",
        "\n",
        "    print(\"regression: \" + str(model_args.regression))\n",
        "    print(\"num_labels: \" + str(num_labels))\n",
        "\n",
        "    train_args = {\"use_multiprocessing\": False,\n",
        "                            \"process_count\": 1,\n",
        "                            \"use_multiprocessing_for_evaluation\": False}\n",
        "    if model_args.regression:\n",
        "      model.train_model(train_df,\n",
        "                      eval_df=eval_df,\n",
        "                      pearson=pearson_corr,\n",
        "                      spearman=spearman_corr,\n",
        "                      args=train_args)\n",
        "    else:\n",
        "      model.train_model(train_df,\n",
        "                      eval_df=eval_df,\n",
        "                      accuracy=accuracy,\n",
        "                      precision=precision,\n",
        "                      recall=recall,\n",
        "                      f1=f1,\n",
        "                      args=train_args)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6br4iadLL6by"
      },
      "outputs": [],
      "source": [
        "def predict(fname, model_path, model=None,\n",
        "            model_type=\"roberta-base\", predict_list=None,\n",
        "          index_list=None, index_colname=\"index\"):\n",
        "\n",
        "    print(model_path)\n",
        "\n",
        "    if model is None:\n",
        "        model = ClassificationModel(model_type.split(\"-\")[0], model_path)\n",
        "\n",
        "    preds, outputs = model.predict(predict_list)\n",
        "    with open(model_path + '/' + fname + '_preds.txt', 'w') as f:\n",
        "        f.write(f\"{index_colname}\\tpred\\outputs\\n\")\n",
        "        for index, pred, output in zip(index_list, preds, outputs):\n",
        "            f.write(f\"{index}\\t{pred}\\t{output}\\n\")\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTwsqqZYObcW"
      },
      "outputs": [],
      "source": [
        "def save_errors(fname, df):\n",
        "  false_positives = df[df[\"pred\"] > df[\"labels\"]]\n",
        "  fp_filename = \"fp_\" + fname + \".csv\"\n",
        "  false_positives.to_csv(fp_filename)\n",
        "  files.download(fp_filename)\n",
        "  false_negatives = df[df[\"pred\"] < df[\"labels\"]]\n",
        "  fn_filename = \"fn_\" + fname + \".csv\"\n",
        "  false_negatives.to_csv(fn_filename)\n",
        "  files.download(fn_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Set parameters."
      ],
      "metadata": {
        "id": "v_u0udBNo24e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-fTzOlmP-sD"
      },
      "outputs": [],
      "source": [
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "train_data = df\n",
        "label_col = \"label\"\n",
        "text_cols = \"text\"\n",
        "predict_index_col = \"pred_index\"\n",
        "model_type = \"roberta-base\"\n",
        "#model_type = \"bert-base-cased\"\n",
        "text_cols = text_cols.split(\",\")\n",
        "output_dir = \"outputs/roberta\"\n",
        "#output_dir = \"outputs/bert\"\n",
        "model = None\n",
        "dev_split_size = 0\n",
        "num_train_epochs = 5\n",
        "train_batch_size=8\n",
        "gradient_accumulation_steps=2\n",
        "balance_labels_trim=False,\n",
        "balance_labels_weights=True,\n",
        "weights = [1, 0.15]\n",
        "\n",
        "print(\"Loading data from %s\" % train_data)\n",
        "train_data = train_data[~train_data[label_col].isnull()]\n",
        "print(\"Loaded %d training examples.\" % len(train_data))\n",
        "print(\"Using %s as label\" % label_col)\n",
        "\n",
        "if len(text_cols) == 1:\n",
        "  train_data = train_data.rename(columns={text_cols[0]: 'text', label_col: 'labels'})\n",
        "  cols = [\"text\", \"labels\", \"pred_index\"]\n",
        "elif len(text_cols) == 2:\n",
        "  train_data = train_data.rename(columns={text_cols[0]: 'text_a',\n",
        "                                          text_cols[1]: 'text_b',\n",
        "                                          label_col: 'labels'})\n",
        "  cols = [\"text_a\", \"text_b\", \"labels\"]\n",
        "else:\n",
        "    print(\"You can have up to 2 texts to classify!\")\n",
        "    exit()\n",
        "\n",
        "train_data = train_data[cols].dropna()\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbvRSIaLqXAx"
      },
      "source": [
        "#Cross Validation\n",
        "\n",
        "This workflow will ask you to sign in to Weights and Biases. Track model performance metrics at the WB dashboards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aV76ClVbT8Ad"
      },
      "outputs": [],
      "source": [
        "n = 5\n",
        "kf = KFold(n_splits=n, random_state=42, shuffle=True)\n",
        "k = 0\n",
        "for train_index, val_index in kf.split(train_data):\n",
        "  print(\"Split %d\" % k)\n",
        "  output_dir_k = output_dir + \"/\" + label_col + \"_k%d\" % k\n",
        "\n",
        "  train_df = train_data.iloc[train_index]\n",
        "  eval_df = train_data.iloc[val_index]\n",
        "  model = train(label_col, train_df, eval_df, text_cols, output_dir=output_dir_k,\n",
        "                          model=model_type, num_labels=2, num_train_epochs=5, balance_labels_weights=balance_labels_weights, weights = weights,\n",
        "                          cross_validate=True)\n",
        "  # Alternatively, use 1 label for training regression models\n",
        "  # model = train(label_col, train_df, eval_df, text_cols, output_dir=output_dir,\n",
        "  #                       model=model_type, num_labels=1, num_train_epochs=5, balance_labels=False, cross_validate=True)\n",
        "\n",
        "  if len(text_cols) == 1:\n",
        "    predict_list = eval_df[\"text\"].tolist()\n",
        "  elif len(text_cols) == 2:\n",
        "    predict_list = eval_df[[\"text_a\", \"text_b\"]].values.tolist()\n",
        "  else:\n",
        "    print(\"You can have up to 2 texts to classify!\")\n",
        "    exit()\n",
        "\n",
        "  index_list = eval_df[predict_index_col].tolist()\n",
        "  fname = label_col + \"_pred\" + \"_split_%d\" % k\n",
        "  preds = predict(fname, output_dir_k, model, model_type, predict_list=predict_list,\n",
        "                    index_list=index_list, index_colname=predict_index_col)\n",
        "\n",
        "  # on the last split, save the false positives/negatives\n",
        "  # if k == (n-1):\n",
        "  #   eval_df[\"pred\"] = preds\n",
        "  #   save_errors(trial_name, eval_df)\n",
        "\n",
        "  k += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESIR2-3VqO9q"
      },
      "source": [
        "#Predict Final\n",
        "\n",
        "This workflow will ask you to sign in to Weights and Biases. Track model performance metrics at the WB dashboards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiwYSMrWrtg7"
      },
      "outputs": [],
      "source": [
        "train_df = train_data\n",
        "eval_df = train_data\n",
        "model = train(label_col, train_df, eval_df, text_cols, output_dir,\n",
        "              model_type, num_labels=2, num_train_epochs=num_train_epochs, balance_labels=False)\n",
        "\n",
        "# Alternatively, use 1 label for training regression models\n",
        "# model = train(label_col, train_df, eval_df, text_cols, output_dir=output_dir,\n",
        "#                         model=model_type, num_labels=1, num_train_epochs=5, balance_labels=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWpJueFy7KyH"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# TODO: Read in the file you want to predict\n",
        "# Reminder: Remove training data from the application task set prior to uploading here\n",
        "app_df = pd.read_csv(\"YOURFILE.csv\")\n",
        "app_df['pred_index'] = range(1, len(app_df) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAsIbna3xtSW"
      },
      "outputs": [],
      "source": [
        "# Mask out numbers and student identifiers\n",
        "app_df[\"text\"] = app_df[\"text\"].apply(lambda x: re.sub('[0-9]+', \"<num>\", x))\n",
        "app_df[\"text\"] = app_df[\"text\"].apply(lambda x: re.sub('(student )[a-z][^a-z]', \"<student>\", x))\n",
        "app_df[\"text\"] = app_df[\"text\"].apply(lambda x: re.sub('(Student )[A-Z]', \"<student>\", x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkupEc4im-Dw"
      },
      "outputs": [],
      "source": [
        "# If the application set is very large, predict in chunks\n",
        "# Otherwise, adapt to predict once\n",
        "chunks = np.array_split(app_df, 25)\n",
        "output_dir_k = output_dir + \"/preds\" # You might have to make this folder in colab first\n",
        "chunk_n = 0\n",
        "for chunk in chunks:\n",
        "  predict_list = chunk[\"text\"].tolist()\n",
        "  index_list = chunk[predict_index_col].tolist()\n",
        "  fname = label_col + \"_pred_%d\" % chunk_n\n",
        "  predict(fname, output_dir_k, model, model_type, predict_list=predict_list,\n",
        "        index_list=index_list, index_colname=predict_index_col)\n",
        "  chunk_n += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSHzwu7ESgRm"
      },
      "outputs": [],
      "source": [
        "# Piece predicted chunks back together again\n",
        "outputfiles = os.listdir(\"outputs/roberta/preds\")\n",
        "output_dfs = []\n",
        "for ofile in outputfiles:\n",
        "  if ofile.startswith(label_col + \"_pred_\"):\n",
        "    ofile_df = pd.read_csv(\"outputs/roberta/preds/\" + ofile, sep=\"\\t\")\n",
        "    ofile_df['index'] = ofile_df.index\n",
        "    ofile_df.reset_index()\n",
        "    ofile_df.columns = ['pred', \"raw\", 'pred_index']\n",
        "    output_dfs.append(ofile_df)\n",
        "\n",
        "pred_df = pd.concat(output_dfs)\n",
        "# Join with original utterances\n",
        "combined_df = pred_df.join(app_df.set_index('pred_index'), on=\"pred_index\")\n",
        "combined_df_sorted = combined_df.sort_values(by=['pred_index'])\n",
        "combined_df_sorted.to_csv(\"predictions.csv\")\n",
        "files.download('predictions.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7XdbL-2Qolqp",
        "v_u0udBNo24e",
        "VbvRSIaLqXAx",
        "ESIR2-3VqO9q"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}